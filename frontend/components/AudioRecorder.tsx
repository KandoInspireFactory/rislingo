/**
 * AudioRecorder component - Audio recording with real-time waveform visualization
 * 
 * Features:
 * - MediaRecorder API for audio recording
 * - Real-time waveform visualization
 * - Microphone access error handling
 * - Automatic recording start and stop
 * 
 * Requirements: 4.1, 4.2
 */

'use client';

import { useEffect, useRef, useState } from 'react';
import WaveformVisualizer from './WaveformVisualizer';
import { RecordingError } from '@/lib/api-client';

interface AudioRecorderProps {
  duration: number; // Recording duration in seconds
  onRecordingComplete: (audioBlob: Blob) => void;
  onError: (error: Error) => void;
  autoStart?: boolean; // Automatically start recording on mount
}

export default function AudioRecorder({
  duration,
  onRecordingComplete,
  onError,
  autoStart = false,
}: AudioRecorderProps) {
  const [isRecording, setIsRecording] = useState(false);
  const [audioStream, setAudioStream] = useState<MediaStream | null>(null);
  const [error, setError] = useState<string | null>(null);
  
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const recordingTimeoutRef = useRef<NodeJS.Timeout | null>(null);
  const mimeTypeRef = useRef<string>('audio/webm');

  // Start recording function
  const startRecording = async () => {
    try {
      // Request microphone access with optimal settings
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 44100,
        },
      });

      setAudioStream(stream);
      audioChunksRef.current = [];

      // Create MediaRecorder instance with fallback MIME types
      let mimeType = 'audio/webm';
      if (!MediaRecorder.isTypeSupported('audio/webm')) {
        if (MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
          mimeType = 'audio/webm;codecs=opus';
        } else if (MediaRecorder.isTypeSupported('audio/mp4')) {
          mimeType = 'audio/mp4';
        } else if (MediaRecorder.isTypeSupported('audio/wav')) {
          mimeType = 'audio/wav';
        } else {
          // Use default (browser will choose)
          mimeType = '';
        }
      }

      console.log('üéôÔ∏è Using MIME type:', mimeType);
      mimeTypeRef.current = mimeType;
      
      const mediaRecorder = new MediaRecorder(stream, mimeType ? {
        mimeType: mimeType,
      } : {});

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = () => {
        console.log('üéôÔ∏è MediaRecorder stopped. Chunks collected:', audioChunksRef.current.length);
        
        if (audioChunksRef.current.length === 0) {
          console.error('‚ùå No audio chunks collected!');
          const error = new RecordingError('Èå≤Èü≥„Éá„Éº„Çø„ÅåÂèéÈõÜ„Åï„Çå„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ');
          setError(error.message);
          onError(error);
          return;
        }
        
        const audioBlob = new Blob(audioChunksRef.current, {
          type: mimeTypeRef.current,
        });
        console.log('üì¶ Audio blob created. Size:', audioBlob.size, 'bytes, Type:', audioBlob.type);
        
        // Clean up stream first
        stream.getTracks().forEach((track) => track.stop());
        setAudioStream(null);
        setIsRecording(false);
        
        // Then trigger completion callback
        onRecordingComplete(audioBlob);
      };

      mediaRecorder.onerror = () => {
        const error = new RecordingError('Èå≤Èü≥‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü„ÄÇ');
        setError(error.message);
        onError(error);
      };

      mediaRecorderRef.current = mediaRecorder;
      // Start recording with timeslice to collect data periodically (every 100ms)
      mediaRecorder.start(100);
      setIsRecording(true);
      setError(null);
      console.log('üéôÔ∏è Recording started');

      // Auto-stop after duration
      console.log(`‚è±Ô∏è Recording will auto-stop in ${duration} seconds`);
      recordingTimeoutRef.current = setTimeout(() => {
        console.log('‚è∞ Auto-stop timeout triggered');
        stopRecording();
      }, duration * 1000);
    } catch (err) {
      handleRecordingError(err);
    }
  };

  // Stop recording function
  const stopRecording = () => {
    console.log('üõë stopRecording called. mediaRecorder state:', mediaRecorderRef.current?.state);
    
    if (!mediaRecorderRef.current) {
      console.warn('‚ö†Ô∏è No mediaRecorder instance');
      return;
    }
    
    // Check if mediaRecorder is in a valid state to stop
    if (mediaRecorderRef.current.state === 'recording') {
      console.log('‚èπÔ∏è Stopping MediaRecorder...');
      mediaRecorderRef.current.stop();
      setIsRecording(false);
    } else if (mediaRecorderRef.current.state === 'paused') {
      console.log('‚è∏Ô∏è MediaRecorder is paused, resuming and stopping...');
      mediaRecorderRef.current.resume();
      mediaRecorderRef.current.stop();
      setIsRecording(false);
    } else {
      console.warn('‚ö†Ô∏è MediaRecorder is not in recording state:', mediaRecorderRef.current.state);
      // If not recording but we have chunks, still trigger completion
      if (audioChunksRef.current.length > 0) {
        console.log('üì¶ Manually triggering completion with existing chunks');
        const audioBlob = new Blob(audioChunksRef.current, {
          type: mimeTypeRef.current,
        });
        onRecordingComplete(audioBlob);
        setIsRecording(false);
        
        // Clean up stream
        if (audioStream) {
          audioStream.getTracks().forEach((track) => track.stop());
          setAudioStream(null);
        }
      }
    }
    
    // Clear timeout
    if (recordingTimeoutRef.current) {
      clearTimeout(recordingTimeoutRef.current);
      recordingTimeoutRef.current = null;
    }
  };

  // Handle recording errors
  const handleRecordingError = (err: unknown) => {
    let errorMessage = 'Èü≥Â£∞Èå≤Èü≥„ÅÆÈñãÂßã„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇ';
    
    if (err instanceof DOMException) {
      if (err.name === 'NotAllowedError') {
        errorMessage = '„Éû„Ç§„ÇØ„Å∏„ÅÆ„Ç¢„ÇØ„Çª„Çπ„ÅåÊãíÂê¶„Åï„Çå„Åæ„Åó„Åü„ÄÇ„Éñ„É©„Ç¶„Ç∂„ÅÆË®≠ÂÆö„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ';
      } else if (err.name === 'NotFoundError') {
        errorMessage = '„Éû„Ç§„ÇØ„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ„Éá„Éê„Ç§„Çπ„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ';
      } else if (err.name === 'NotReadableError') {
        errorMessage = '„Éû„Ç§„ÇØ„Åå‰ªñ„ÅÆ„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„Åß‰ΩøÁî®‰∏≠„Åß„Åô„ÄÇ';
      } else if (err.name === 'OverconstrainedError') {
        errorMessage = '„Éû„Ç§„ÇØ„ÅÆË®≠ÂÆö„ÅåÂØæÂøú„Åó„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ';
      }
    }
    
    setError(errorMessage);
    onError(new RecordingError(errorMessage));
  };

  // Auto-start recording if enabled
  useEffect(() => {
    if (autoStart) {
      startRecording();
    }

    // Cleanup on unmount
    return () => {
      if (recordingTimeoutRef.current) {
        clearTimeout(recordingTimeoutRef.current);
      }
      if (audioStream) {
        audioStream.getTracks().forEach((track) => track.stop());
      }
    };
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [autoStart]);

  return (
    <div className="flex flex-col items-center justify-center space-y-4">
      {/* Recording indicator */}
      {isRecording && (
        <div className="flex items-center space-x-2">
          <div className="w-3 h-3 bg-red-500 rounded-full animate-pulse" />
          <span className="text-sm font-medium text-gray-700">Èå≤Èü≥‰∏≠...</span>
        </div>
      )}

      {/* Waveform visualizer */}
      <WaveformVisualizer audioStream={audioStream} isRecording={isRecording} />

      {/* Error message */}
      {error && (
        <div className="px-4 py-2 bg-red-50 border border-red-200 rounded-lg">
          <p className="text-sm text-red-600">{error}</p>
        </div>
      )}

      {/* Manual controls (if not auto-start) */}
      {!autoStart && (
        <div className="flex space-x-4">
          {!isRecording ? (
            <button
              onClick={startRecording}
              className="px-6 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 transition-colors"
            >
              Èå≤Èü≥ÈñãÂßã
            </button>
          ) : (
            <button
              onClick={stopRecording}
              className="px-6 py-2 bg-red-600 text-white rounded-lg hover:bg-red-700 transition-colors"
            >
              Èå≤Èü≥ÂÅúÊ≠¢
            </button>
          )}
        </div>
      )}
    </div>
  );
}
